# DeepSeek-OCR CPU è¿è¡Œé—®é¢˜å®Œæ•´æ’æŸ¥æŒ‡å—

## é—®é¢˜ç°è±¡

åœ¨ CPU ä¸Šè¿è¡Œ DeepSeek-OCR-2 æ—¶å‡ºç°é”™è¯¯ï¼š
```
RuntimeError: Input type (c10::BFloat16) and bias type (float) should be the same
```

## æ ¹æœ¬åŸå› åˆ†æ

### ğŸ”´ æ ¸å¿ƒé—®é¢˜ï¼šæ•°æ®ç±»å‹ä¸åŒ¹é…

DeepSeek-OCR-2 çš„è®¾è®¡ç›®æ ‡æ˜¯åœ¨ **CUDA GPU** ä¸Šä½¿ç”¨ **bfloat16** è¿›è¡Œæ¨ç†ï¼Œä½†åœ¨ CPU ä¸Šï¼š
1. CPU çš„ bfloat16 æ”¯æŒä¸å®Œæ•´
2. æŸäº›æ“ä½œï¼ˆå¦‚å·ç§¯ï¼‰è¦æ±‚è¾“å…¥å’Œæƒé‡å¿…é¡»æ˜¯ç›¸åŒçš„æ•°æ®ç±»å‹
3. å³ä½¿æˆ‘ä»¬æŒ‡å®š `torch_dtype=torch.float32`ï¼Œæ¨¡å‹å†…éƒ¨ä»æœ‰éƒ¨åˆ†ä½¿ç”¨ bfloat16

### ğŸ” é—®é¢˜å±‚æ¬¡åˆ†æ

```
ç¬¬1å±‚ï¼šAPI å…¼å®¹æ€§é—®é¢˜
â”œâ”€ transformers ç‰ˆæœ¬ä¸å…¼å®¹
â”œâ”€ LlamaFlashAttention2 ä¸å­˜åœ¨ï¼ˆæ–°ç‰ˆå·²é‡å‘½åï¼‰
â””â”€ ç¡¬ç¼–ç  .cuda() è°ƒç”¨

ç¬¬2å±‚ï¼šé…ç½®å±‚é—®é¢˜
â”œâ”€ config.json ä¸­ torch_dtype è®¾ä¸º "bfloat16"
â””â”€ æ¨¡å‹åˆå§‹åŒ–æ—¶ä½¿ç”¨é…ç½®ä¸­çš„ dtype

ç¬¬3å±‚ï¼šæƒé‡æ–‡ä»¶é—®é¢˜ï¼ˆæœ€æ·±å±‚ï¼‰
â”œâ”€ safetensors æ–‡ä»¶ä¸­æƒé‡ä»¥ bfloat16 æ ¼å¼ä¿å­˜
â”œâ”€ åŠ è½½åå³ä½¿è½¬æ¢å‚æ•°ï¼ŒæŸäº›å±‚ä»ä¿æŒ bfloat16
â””â”€ å›¾åƒæ•°æ®åœ¨ forward è¿‡ç¨‹ä¸­è¢«è½¬ä¸º bfloat16
```

## ä¿®å¤æ­¥éª¤ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰

### âœ… ä¿®å¤ 1ï¼šä¿®å¤ deepencoderv2.py çš„æ•°æ®ç±»å‹åŒ¹é…ï¼ˆæœ€å…³é”®ï¼‰

**ä½ç½®**ï¼š`/Users/lifeng/data/models/deepseek-ai/DeepSeek-OCR-2/deepencoderv2.py`

**é—®é¢˜**ï¼šå·ç§¯å±‚ `patch_embed.proj` çš„è¾“å…¥æ˜¯ bfloat16ï¼Œä½† bias æ˜¯ float32

**è§£å†³æ–¹æ¡ˆ**ï¼šåœ¨ `PatchEmbed.forward()` æ–¹æ³•ä¸­ï¼ˆçº¦ç¬¬956è¡Œï¼‰æ·»åŠ ç±»å‹è½¬æ¢ï¼š

```python
def forward(self, x: torch.Tensor) -> torch.Tensor:
    # å¼ºåˆ¶è½¬æ¢è¾“å…¥ä¸ºä¸æƒé‡ç›¸åŒçš„ dtype
    if x.dtype != self.proj.weight.dtype:
        x = x.to(self.proj.weight.dtype)
    x = self.proj(x)
    # B C H W -> B H W C
    x = x.permute(0, 2, 3, 1)
    return x
```

**åŸç†**ï¼š
- PyTorch çš„ Conv2d è¦æ±‚è¾“å…¥ã€æƒé‡ã€bias çš„æ•°æ®ç±»å‹å¿…é¡»ä¸€è‡´
- è¿™ä¸ªè¡¥ä¸è®©è¾“å…¥æ•°æ®è‡ªåŠ¨é€‚é…æƒé‡çš„æ•°æ®ç±»å‹
- æ— è®ºæƒé‡æ˜¯ bfloat16 è¿˜æ˜¯ float32ï¼Œéƒ½èƒ½æ­£å¸¸å·¥ä½œ

**ä¸ºä»€ä¹ˆè¿™æ˜¯æœ€å…³é”®çš„ä¿®å¤**ï¼š
- å…¶ä»–ä¿®å¤åªæ˜¯è®©æ¨¡å‹èƒ½åŠ è½½ï¼Œä½†è¿™ä¸ªä¿®å¤è®©æ¨¡å‹èƒ½è¿è¡Œ
- ç›´æ¥è§£å†³äº†è¿è¡Œæ—¶çš„æ•°æ®ç±»å‹ä¸åŒ¹é…é—®é¢˜
- æ˜¯æœ€å°ä¾µå…¥æ€§çš„ä¿®å¤ï¼ˆåªåŠ 3è¡Œä»£ç ï¼‰

### âœ… ä¿®å¤ 2ï¼šä¿®æ”¹ config.json

**ä½ç½®**ï¼š`/Users/lifeng/data/models/deepseek-ai/DeepSeek-OCR-2/config.json`

**ä¿®æ”¹**ï¼š
```bash
sed -i '' 's/"torch_dtype": "bfloat16"/"torch_dtype": "float32"/g' config.json
```

**ä½œç”¨**ï¼š
- è®©æ¨¡å‹åˆå§‹åŒ–æ—¶é»˜è®¤ä½¿ç”¨ float32
- å‡å°‘æ•°æ®ç±»å‹è½¬æ¢çš„å¤æ‚åº¦

**é‡è¦æ€§**ï¼šä¸­ç­‰ï¼ˆé…åˆä¿®å¤1ä½¿ç”¨ï¼‰

### âœ… ä¿®å¤ 3ï¼šä¿®å¤ transformers API å…¼å®¹æ€§

**ä½ç½®**ï¼š
- `modeling_deepseekv2.py`
- `modeling_deepseekocr2.py`

**ä¿®æ”¹**ï¼š
```bash
# ä¿®å¤ LlamaFlashAttention2 â†’ LlamaAttention
sed -i '' 's/LlamaFlashAttention2/LlamaAttention/g' modeling_deepseekv2.py

# ä¿®å¤ç¡¬ç¼–ç  CUDA
sed -i '' 's/\.cuda()/.to(self.device)/g' modeling_deepseekocr2.py
```

**ä½œç”¨**ï¼š
- è®©æ¨¡å‹èƒ½åœ¨æ–°ç‰ˆ transformers å’Œé CUDA è®¾å¤‡ä¸ŠåŠ è½½
- è§£å†³åŠ è½½é˜¶æ®µçš„å…¼å®¹æ€§é—®é¢˜

**é‡è¦æ€§**ï¼šé«˜ï¼ˆå¿…é¡»ä¿®å¤ï¼Œå¦åˆ™æ¨¡å‹æ— æ³•åŠ è½½ï¼‰

### âœ… ä¿®å¤ 4ï¼šä½¿ç”¨æ­£ç¡®çš„ transformers ç‰ˆæœ¬

**è¦æ±‚**ï¼š`transformers==4.46.3`

**åŸå› **ï¼š
- DeepSeek-OCR-2 æ˜¯åŸºäº transformers 4.46.3 å¼€å‘çš„
- æ–°ç‰ˆæœ¬ï¼ˆå¦‚ 4.57.3ï¼‰çš„ API æœ‰ç ´åæ€§å˜æ›´
- ä¾‹å¦‚ï¼š`DynamicCache.seen_tokens` å±æ€§è¢«ç§»é™¤

**å®‰è£…**ï¼š
```bash
pip install transformers==4.46.3
```

**å†²çªå¤„ç†**ï¼š
- ä¸ qwen-ttsï¼ˆéœ€è¦ 4.57.3ï¼‰å†²çª
- å»ºè®®ä¸º OCR åˆ›å»ºç‹¬ç«‹çš„è™šæ‹Ÿç¯å¢ƒ

### ğŸ§¹ è¾…åŠ©æ­¥éª¤ï¼šæ¸…é™¤ç¼“å­˜

**å¿…é¡»æ‰§è¡Œ**ï¼š
```bash
rm -rf ~/.cache/huggingface/modules/transformers_modules/DeepSeek-OCR-2
```

**åŸå› **ï¼š
- transformers ä¼šç¼“å­˜æ¨¡å‹ä»£ç 
- ä¿®æ”¹æ¨¡å‹æ–‡ä»¶åå¿…é¡»æ¸…é™¤ç¼“å­˜
- å¦åˆ™ä»ä½¿ç”¨æ—§çš„ï¼ˆæœªä¿®å¤çš„ï¼‰ä»£ç 

## ä¸ºä»€ä¹ˆå‚è€ƒé¡¹ç›®ä¹Ÿé‡åˆ°åŒæ ·é—®é¢˜

æµ‹è¯•å‘ç°ï¼Œå‚è€ƒé¡¹ç›® `deepseekocrGradio` ä¹Ÿæœ‰ç›¸åŒé—®é¢˜ï¼

**åŸå› **ï¼š
- ä»–ä»¬ä¹Ÿæ˜¯ç”¨ `transformers.AutoModel` åŠ è½½æ¨¡å‹
- ä¹Ÿé‡åˆ°äº† bfloat16 æ•°æ®ç±»å‹ä¸åŒ¹é…çš„é—®é¢˜
- å¯èƒ½åœ¨ç‰¹å®šç¯å¢ƒä¸‹èƒ½å·¥ä½œï¼ˆä¾‹å¦‚ä»–ä»¬æ²¡åœ¨ CPU ä¸ŠçœŸæ­£æµ‹è¯•è¿‡ï¼‰

**æ•™è®­**ï¼š
- ä¸è¦ç›²ç›®ç›¸ä¿¡"å‚è€ƒé¡¹ç›®èƒ½å·¥ä½œ"
- éœ€è¦å®é™…è¿è¡Œæµ‹è¯•éªŒè¯

## æ ¹æœ¬é—®é¢˜ï¼šè®¾è®¡å‡è®¾ä¸åŒ¹é…

### DeepSeek-OCR çš„è®¾è®¡å‡è®¾

1. **å‡è®¾è¿è¡Œåœ¨ CUDA GPU ä¸Š**
   - CUDA å¯¹ bfloat16 æœ‰å®Œæ•´æ”¯æŒ
   - bfloat16 å¯ä»¥æå‡æ€§èƒ½å’Œå‡å°‘æ˜¾å­˜

2. **å‡è®¾ä½¿ç”¨ transformers 4.46.3**
   - ä»£ç ä¾èµ–ç‰¹å®šç‰ˆæœ¬çš„ API
   - æ–°ç‰ˆæœ¬æœ‰ç ´åæ€§å˜æ›´

3. **å‡è®¾ä½¿ç”¨ bfloat16 è®­ç»ƒå’Œæ¨ç†**
   - æ¨¡å‹æƒé‡ä»¥ bfloat16 æ ¼å¼ä¿å­˜åœ¨ safetensors ä¸­
   - config.json é…ç½®ä¸º bfloat16

### æˆ‘ä»¬çš„è¿è¡Œç¯å¢ƒ

1. **CPU æ¨ç†ï¼ˆApple M2 Maxï¼‰**
   - CPU å¯¹ bfloat16 æ”¯æŒæœ‰é™
   - æŸäº›æ“ä½œï¼ˆå¦‚ Conv2dï¼‰è¦æ±‚ä¸¥æ ¼çš„ç±»å‹åŒ¹é…

2. **éœ€è¦ä¸å…¶ä»–æ¨¡å—å…±å­˜**
   - TTS æ¨¡å—éœ€è¦ transformers 4.57.3
   - ç‰ˆæœ¬å†²çªå¯¼è‡´éœ€è¦ç‹¬ç«‹ç¯å¢ƒ

## é€šç”¨è§£å†³æ€è·¯ï¼ˆé€‚ç”¨äºç±»ä¼¼é—®é¢˜ï¼‰

### ğŸ¯ é‡åˆ° "Input type and bias type should be the same" é”™è¯¯æ—¶

**æ­¥éª¤ 1ï¼šç¡®è®¤æ•°æ®ç±»å‹æ¥æº**
```python
# æ£€æŸ¥æ¨¡å‹æƒé‡çš„ dtype
import safetensors
with safetensors.safe_open('model.safetensors', framework='pt') as f:
    first_key = list(f.keys())[0]
    tensor = f.get_tensor(first_key)
    print(f'æƒé‡ dtype: {tensor.dtype}')
```

**æ­¥éª¤ 2ï¼šæ£€æŸ¥é…ç½®æ–‡ä»¶**
```bash
grep "torch_dtype" config.json
```

**æ­¥éª¤ 3ï¼šåœ¨å‡ºé”™çš„å±‚æ·»åŠ ç±»å‹è½¬æ¢**
- æ‰¾åˆ°æŠ¥é”™çš„å…·ä½“ä½ç½®ï¼ˆé€šå¸¸æ˜¯ Conv2dã€Linear ç­‰ï¼‰
- åœ¨è¯¥å±‚çš„ forward æ–¹æ³•å¼€å§‹å¤„æ·»åŠ ï¼š
  ```python
  if x.dtype != self.weight.dtype:
      x = x.to(self.weight.dtype)
  ```

### ğŸ¯ é‡åˆ° transformers API å…¼å®¹æ€§é—®é¢˜æ—¶

**æ­¥éª¤ 1ï¼šæŸ¥çœ‹å®˜æ–¹ requirements.txt**
- æ£€æŸ¥é¡¹ç›®æŒ‡å®šçš„ transformers ç‰ˆæœ¬
- ä½¿ç”¨å®Œå…¨ç›¸åŒçš„ç‰ˆæœ¬

**æ­¥éª¤ 2ï¼šæ£€æŸ¥ ImportError**
- å¦‚æœæç¤ºæŸä¸ªç±»ä¸å­˜åœ¨ï¼ˆå¦‚ LlamaFlashAttention2ï¼‰
- åœ¨æ¨¡å‹æ–‡ä»¶ä¸­æœç´¢è¯¥ç±»å
- æ›¿æ¢ä¸ºæ–°ç‰ˆæœ¬ä¸­çš„ç­‰ä»·ç±»ï¼ˆæŸ¥é˜… transformers æ›´æ–°æ—¥å¿—ï¼‰

**æ­¥éª¤ 3ï¼šåˆ›å»ºç‹¬ç«‹ç¯å¢ƒ**
```bash
python -m venv model_env
source model_env/bin/activate
pip install transformers==æŒ‡å®šç‰ˆæœ¬
```

### ğŸ¯ é‡åˆ°è®¾å¤‡ç›¸å…³é”™è¯¯ï¼ˆ.cuda()ï¼‰æ—¶

**å…¨å±€æ›¿æ¢**ï¼š
```bash
# åœ¨æ¨¡å‹ç›®å½•ä¸‹
find . -name "*.py" -exec sed -i '' 's/\.cuda()/.to(self.device)/g' {} \;
```

**æ³¨æ„**ï¼š
- ç¡®ä¿æ¨¡å‹ç±»æœ‰ `self.device` å±æ€§
- æˆ–è€…æ›¿æ¢ä¸º `.to(device)`ï¼Œä½†éœ€è¦ç¡®ä¿ device å˜é‡å­˜åœ¨

## ä¿®å¤è„šæœ¬ï¼ˆè‡ªåŠ¨åŒ–å·¥å…·ï¼‰

åˆ›å»ºä¸€ä¸ªä¸€é”®ä¿®å¤è„šæœ¬ï¼š

```bash
#!/bin/bash
# fix_deepseek_ocr.sh

MODEL_PATH="/Users/lifeng/data/models/deepseek-ai/DeepSeek-OCR-2"

echo "ğŸ”§ å¼€å§‹ä¿®å¤ DeepSeek-OCR-2..."

# 1. ä¿®å¤ API å…¼å®¹æ€§
echo "1. ä¿®å¤ transformers API å…¼å®¹æ€§..."
cd "$MODEL_PATH"
sed -i '' 's/LlamaFlashAttention2/LlamaAttention/g' modeling_deepseekv2.py
sed -i '' 's/\.cuda()/.to(self.device)/g' modeling_deepseekocr2.py

# 2. ä¿®æ”¹ config.json
echo "2. ä¿®æ”¹ config.json..."
cp config.json config.json.bak
sed -i '' 's/"torch_dtype": "bfloat16"/"torch_dtype": "float32"/g' config.json

# 3. ä¿®å¤ deepencoderv2.py
echo "3. ä¿®å¤ deepencoderv2.py æ•°æ®ç±»å‹åŒ¹é…..."
# æ£€æŸ¥æ˜¯å¦å·²ä¿®å¤
if ! grep -q "if x.dtype != self.proj.weight.dtype:" deepencoderv2.py; then
    sed -i '' '956i\
        # å¼ºåˆ¶è½¬æ¢è¾“å…¥ä¸ºä¸æƒé‡ç›¸åŒçš„ dtype\
        if x.dtype != self.proj.weight.dtype:\
            x = x.to(self.proj.weight.dtype)\
' deepencoderv2.py
    echo "   âœ… å·²æ·»åŠ ç±»å‹è½¬æ¢è¡¥ä¸"
else
    echo "   â­ï¸  å·²å­˜åœ¨ä¿®å¤ï¼Œè·³è¿‡"
fi

# 4. æ¸…é™¤ç¼“å­˜
echo "4. æ¸…é™¤ transformers ç¼“å­˜..."
rm -rf ~/.cache/huggingface/modules/transformers_modules/DeepSeek-OCR-2

echo "âœ… ä¿®å¤å®Œæˆï¼"
echo ""
echo "ğŸ“Œ ä¸‹ä¸€æ­¥ï¼š"
echo "  1. å®‰è£…æ­£ç¡®çš„ transformers ç‰ˆæœ¬: pip install transformers==4.46.3"
echo "  2. æµ‹è¯•æ¨¡å‹: python test_ocr_result.py"
```

## éªŒè¯ä¿®å¤æ˜¯å¦æˆåŠŸ

è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š

```python
from transformers import AutoModel, AutoTokenizer
import torch

MODEL_PATH = '/Users/lifeng/data/models/deepseek-ai/DeepSeek-OCR-2'

# åŠ è½½æ¨¡å‹
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
model = AutoModel.from_pretrained(
    MODEL_PATH,
    trust_remote_code=True,
    torch_dtype=torch.float32,
)
model = model.eval().to('cpu')

# æµ‹è¯•æ¨ç†
result = model.infer(
    tokenizer=tokenizer,
    prompt='<<image>>\n<<|grounding|>>Convert the document to markdown.',
    image_file='test.png',
    output_path='/tmp/ocr_output',
    base_size=1024,
    image_size=1024,
    crop_mode=False,
    eval_mode=True,
)

if result:
    print("âœ… ä¿®å¤æˆåŠŸï¼æ¨¡å‹å¯ä»¥æ­£å¸¸è¿è¡Œ")
else:
    print("âŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
```

## æ€»ç»“ï¼š3ä¸ªå…³é”®ä¿®å¤

| ä¿®å¤ | é‡è¦æ€§ | ä½œç”¨ | ä¸ä¿®å¤ä¼šæ€æ · |
|------|--------|------|-------------|
| **deepencoderv2.py ç±»å‹è½¬æ¢** | ğŸ”´ æœ€é«˜ | è§£å†³è¿è¡Œæ—¶é”™è¯¯ | æ— æ³•è¿›è¡Œæ¨ç†ï¼Œç›´æ¥æŠ¥é”™ |
| **transformers API å…¼å®¹** | ğŸŸ¡ é«˜ | è§£å†³åŠ è½½é”™è¯¯ | æ— æ³•åŠ è½½æ¨¡å‹ |
| **config.json dtype** | ğŸŸ¢ ä¸­ | ä¼˜åŒ–æ€§èƒ½ | å¯ä»¥è¿è¡Œä½†å¯èƒ½æœ‰è­¦å‘Š |

## ç»éªŒæ•™è®­

1. âœ… **æ°¸è¿œéªŒè¯å‚è€ƒä»£ç **
   - ä¸è¦å‡è®¾åˆ«äººçš„ä»£ç åœ¨ä½ çš„ç¯å¢ƒèƒ½å·¥ä½œ
   - å®é™…è¿è¡Œæµ‹è¯•æ‰æ˜¯ç‹é“

2. âœ… **ç†è§£æ ¹æœ¬åŸå› æ¯”å¤åˆ¶ç²˜è´´é‡è¦**
   - çŸ¥é“ä¸ºä»€ä¹ˆå¤±è´¥ï¼Œæ‰èƒ½çŸ¥é“å¦‚ä½•ä¿®å¤
   - æ·±å…¥ç†è§£é—®é¢˜ï¼Œæ‰èƒ½ä¸¾ä¸€åä¸‰

3. âœ… **åˆ†å±‚æ’æŸ¥é—®é¢˜**
   - API å…¼å®¹æ€§ â†’ é…ç½® â†’ ä»£ç é€»è¾‘ â†’ æ•°æ®ç±»å‹
   - ä»å¤–åˆ°å†…ï¼Œé€å±‚æ·±å…¥

4. âœ… **å·¥å…·è¾…åŠ©æ’æŸ¥**
   - ä½¿ç”¨ Python æ£€æŸ¥æ•°æ®ç±»å‹
   - ä½¿ç”¨ grep æŸ¥æ‰¾é—®é¢˜ä»£ç 
   - ä½¿ç”¨ sed æ‰¹é‡ä¿®æ”¹

5. âœ… **æ–‡æ¡£åŒ–ä¿®å¤è¿‡ç¨‹**
   - è®°å½•é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ
   - ä¸‹æ¬¡é‡åˆ°ç±»ä¼¼é—®é¢˜å¯å¿«é€Ÿè§£å†³

## ä¸‹æ¬¡é‡åˆ°ç±»ä¼¼é—®é¢˜çš„æ£€æŸ¥æ¸…å•

- [ ] ç¡®è®¤æ¨¡å‹çš„ç›®æ ‡è¿è¡Œç¯å¢ƒï¼ˆCUDA/CPU/MPSï¼‰
- [ ] æ£€æŸ¥ transformers ç‰ˆæœ¬è¦æ±‚
- [ ] æ£€æŸ¥ config.json ä¸­çš„ torch_dtype
- [ ] æ£€æŸ¥ safetensors ä¸­æƒé‡çš„å®é™… dtype
- [ ] æŸ¥æ‰¾ç¡¬ç¼–ç çš„ .cuda() è°ƒç”¨
- [ ] åœ¨å‡ºé”™çš„å±‚æ·»åŠ ç±»å‹è½¬æ¢
- [ ] æ¸…é™¤ transformers ç¼“å­˜
- [ ] åˆ›å»ºç‹¬ç«‹çš„è™šæ‹Ÿç¯å¢ƒï¼ˆå¦‚æœ‰ç‰ˆæœ¬å†²çªï¼‰
- [ ] éªŒè¯ä¿®å¤åçš„æ¨ç†ç»“æœ

---

**æœ€åå»ºè®®**ï¼šä¿å­˜è¿™ä»½æ–‡æ¡£å’Œä¿®å¤è„šæœ¬ï¼Œä¸‹æ¬¡é‡åˆ°ç±»ä¼¼çš„æ¨¡å‹ç§»æ¤é—®é¢˜æ—¶å¯ä»¥å¿«é€Ÿå‚è€ƒï¼
